

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>1.8. Ensemble learning &#8212; Machine Learning book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '1_Process_Modelling/Split_notebooks/4_ML_Supervised_learning_Algorithms-7';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="1.9. Multi-class and multi-output" href="4_ML_Supervised_learning_Algorithms-8.html" />
    <link rel="prev" title="1.7. Tree-base model" href="4_ML_Supervised_learning_Algorithms-6.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../_jupyter_book_files/intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../_jupyter_book_files/intro.html">
                    Welcome to Dat’s Notebook
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Process Modeling</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="0_toc_eda.html">1. Statistic and EDA</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="1_Statistics_and_EDA-0.html">1.1. Data Analyst Process</a></li>
<li class="toctree-l2"><a class="reference internal" href="1_Statistics_and_EDA-1.html">1.2. Read datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="1_Statistics_and_EDA-2.html">1.3. Explore data analysis (EDA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="1_Statistics_and_EDA-3.html">1.4. Description statistic</a></li>
<li class="toctree-l2"><a class="reference internal" href="1_Statistics_and_EDA-4.html">1.5. Inferential statistic</a></li>
<li class="toctree-l2"><a class="reference internal" href="1_Statistics_and_EDA-5.html">1.6. Kiểm định giả thuyết (Hypothesis testing)</a></li>
<li class="toctree-l2"><a class="reference internal" href="1_Statistics_and_EDA-6.html">1.7. ANOVA</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="0_toc_fe.html">2. Feature Engineering</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="2_Feature_engineering-1.html">2.1. Custom Transforms Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_Feature_engineering-2.html">2.2. Feature extraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_Feature_engineering-3.html">2.3. Variable Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_Feature_engineering-4.html">2.4. Missing Imputation</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_Feature_engineering-5.html">2.5. Categorical Encoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_Feature_engineering-6.html">2.6. Feature transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_Feature_engineering-7.html">2.7. Discretisation</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_Feature_engineering-8.html">2.8. Outliers</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_Feature_engineering-9.html">2.9. Feature scaling</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_Feature_engineering-10.html">2.10. Feature selection</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="0_toc_imb.html">3. Imbalance Dataset Handling</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="3_Imbalance_data_handling-1.html">3.1. Data-level approaches</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_Imbalance_data_handling-2.html">3.2. Cost sensitive approaches</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_Imbalance_data_handling-3.html">3.3. Ensemble approaches</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_Imbalance_data_handling-4.html">3.4. Ensemble approaches</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="0_toc_fs.html">4. Feature Selection</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="3_Feature_selection_and_decomposition-1.html">4.1. Filter methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_Feature_selection_and_decomposition-2.html">4.2. Wrapped methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_Feature_selection_and_decomposition-3.html">4.3. Embedded methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_Feature_selection_and_decomposition-4.html">4.4. Hybrid methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_Feature_selection_and_decomposition-5.html">4.5. Feature decomposition</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="0_toc_eva.html">5. Evaluation Metrics</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="5_Evaluation_metrics-0.html">5.1. Define scorer</a></li>
<li class="toctree-l2"><a class="reference internal" href="5_Evaluation_metrics-1.html">5.2. Classification metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="5_Evaluation_metrics-2.html">5.3. Regression metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="5_Evaluation_metrics-3.html">5.4. Clustering metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="5_Evaluation_metrics-4.html">5.5. Pairwise metrics</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="6_Models_monitoring_production-0.html">6. Model Monitoring</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="6_Models_monitoring_production-1.html">6.7. Functional level monitoring</a></li>
<li class="toctree-l2"><a class="reference internal" href="6_Models_monitoring_production-2.html">6.8. Operational level monitoring</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ML/DL Algorithms</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="0_toc_ml_su.html">1. ML Supervised Learning</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="4_ML_Supervised_learning_Algorithms-0.html">1.1. Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Supervised_learning_Algorithms-1.html">1.2. Naive Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Supervised_learning_Algorithms-2.html">1.3. Discriminant Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Supervised_learning_Algorithms-3.html">1.4. Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Supervised_learning_Algorithms-4.html">1.5. Support Vector Machines (SVM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Supervised_learning_Algorithms-5.html">1.6. Nearest neighbors</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Supervised_learning_Algorithms-6.html">1.7. Tree-base model</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">1.8. Ensemble learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Supervised_learning_Algorithms-8.html">1.9. Multi-class and multi-output</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Supervised_learning_Algorithms-9.html">1.10. Neural network models</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="0_toc_ml_unsu.html">2. ML Unsupervised Learning</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Unsupervised_learning_Algorithms-0.html">2.1. Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Unsupervised_learning_Algorithms-1.html">2.2. Decomposing components</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Unsupervised_learning_Algorithms-2.html">2.3. Manifold learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Unsupervised_learning_Algorithms-3.html">2.4. Novelty and Outlier Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Unsupervised_learning_Algorithms-4.html">2.5. Neural network</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="0_toc_dl.html">3. Deep Learning</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="4_DL_Algorithms-0.html">3.1. Neural Network</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">My Modules</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../3_Mathematics/0_toc.html">1. Mathematics</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../3_Mathematics/1_Linear_algebra.html">1.1. Linear algebra</a></li>



<li class="toctree-l2"><a class="reference internal" href="../../3_Mathematics/2_Calculus_and_optimization.html">1.5. Calculus and optimization</a></li>






<li class="toctree-l2"><a class="reference internal" href="../../3_Mathematics/3_Distribution_and_statistic.html">1.12. Distribution and statistics</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../3_Mathematics/4_Information_theory.html">1.14. Information theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../3_Mathematics/5_Graph_theory.html">1.15. Graph theory</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../4_Programming/0_toc.html">2. Programming</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../4_Programming/1_SQL.html">2.1. SQL</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../4_Programming/2_noSQL.html">2.2. noSQL</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../4_Programming/3_pySpark.html">2.3. pySpark</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../4_Programming/4_Python.html">2.4. Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../4_Programming/6_Git.html">2.5. Git</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../4_Programming/7_Docker.html">2.6. Docker</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../2_My_Modules/1_Data_Cleaning.html">3. Data cleaning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../2_My_Modules/2_Connection.html">4. Data connection</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/datkt1998/DS_learning_book" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/1_Process_Modelling/Split_notebooks/4_ML_Supervised_learning_Algorithms-7.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Ensemble learning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#weighted">1.8.1. Weighted</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bagging">1.8.2. Bagging</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest">1.8.2.1. Random Forest</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#extremely-randomized-trees-extra-tree">1.8.2.2. Extremely Randomized Trees (extra-tree)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bagging-meta-estimator">1.8.2.3. Bagging meta-estimator</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#boosting">1.8.3. Boosting</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adaboost">1.8.3.1. AdaBoost</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-boosting">1.8.3.2. Gradient Boosting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#xgboost">1.8.3.3. XGBoost</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lightgbm">1.8.3.4. LightGBM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stacking">1.8.4. Stacking</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="ensemble-learning">
<h1><span class="section-number">1.8. </span>Ensemble learning<a class="headerlink" href="#ensemble-learning" title="Permalink to this heading">#</a></h1>
<section id="weighted">
<h2><span class="section-number">1.8.1. </span>Weighted<a class="headerlink" href="#weighted" title="Permalink to this heading">#</a></h2>
<p>Sử dụng kết hợp nhiều model và kết hợp lại thành 1 meta-model:</p>
<ul class="simple">
<li><p>Với regression: Average outcome</p></li>
<li><p>Với Classification: majority label</p></li>
</ul>
</section>
<section id="bagging">
<h2><span class="section-number">1.8.2. </span>Bagging<a class="headerlink" href="#bagging" title="Permalink to this heading">#</a></h2>
<p>Xây dựng các models cùng lại nhưng train trên các subsamples khác nhau từ raw-sample, các subsample này được sinh ra từ phương pháp <strong>bootstraping with replacement</strong>.</p>
<p>Các model này độc lập và song song với nhau, kết quả cuối cùng sử dụng trung bình cộng các decision rules hoặc <code class="docutils literal notranslate"><span class="pre">majority</span> <span class="pre">class</span></code></p>
<p>–&gt; Mục tiêu là giảm <strong>variance</strong> - áp dụng cho các model đã có sẵn <strong>bias thấp</strong> và đang bị <strong>variance cao</strong></p>
<section id="random-forest">
<h3><span class="section-number">1.8.2.1. </span>Random Forest<a class="headerlink" href="#random-forest" title="Permalink to this heading">#</a></h3>
<p>RF ngoài việc tạo <strong>bootstrap with replacement subsample by records</strong> từ raw sample thì còn thực hiện <strong>bootstrap without replacement by variables</strong></p>
<p>Tuy nhiên FR là 1 blackbox model, khác với simple decision tree.</p>
<p>–&gt; giúp giải quyết vấn đề khi input đầu vào thiếu 1 số features (chứa nan và không muốn imputation)</p>
<p><strong>1. out of bag score (oob)</strong></p>
<ul class="simple">
<li><p><strong>OOB sample</strong> là tập obs không nằm trong tập train (dc bootstrap trong total obs) của mỗi single tree.</p></li>
<li><p><strong>OOB score</strong> là một cách validate RF model, thông qua tính tỷ lệ obs trong oob sample dc dự đoán đúng bởi single tree tương ứng. ví dụ: <code class="docutils literal notranslate"><span class="pre">xi</span></code> không thuộc tập train của các tree <code class="docutils literal notranslate"><span class="pre">DT1</span></code>, <code class="docutils literal notranslate"><span class="pre">DT2</span></code>,… ,<code class="docutils literal notranslate"><span class="pre">DTn</span></code>, sẽ được dự báo bởi các tree này, nếu majority voting == real labels —&gt; xi là 1 obs predict đúng. làm tương tự vs các obs khác và tính tỷ lệ predict đúng.</p></li>
<li><p><strong>OOB error</strong> = 1 - <strong>OOB score</strong>: thể hiện tỷ lệ obs oob dự đoán sai.</p></li>
</ul>
<p>OOB error is a way similar a validation score but in <strong>smaller dataset</strong>(not suitable for split train + val dataset), check the error rate change by number of estimator</p>
<p><img alt="image.png" src="../../_images/oob.png" /></p>
<p><strong>2. Variable Importance</strong> (<code class="docutils literal notranslate"><span class="pre">model.feature_importances_</span></code>)</p>
<ul class="simple">
<li><p><strong>decrease in accuracy of the model</strong>: Mức độ giảm độ chính xác của model thông qua oob_score nếu biến này được hoán đổi random value giữa các records 1 cách ngẫu nhiên. Nếu mức decrease in accuracy càng lớn thì biến đó bằng quan trọng.</p></li>
</ul>
<p><img alt="image.png" src="../../_images/de_acc_rf.png" /></p>
<ul class="simple">
<li><p><strong>Giá trị giảm trung bình của gini impurity score</strong>: TÍnh mức độ giảm điểm Gini impurity score trên node khi có biến đó được sử dụng, tính toán trên bộ train data, thay vì tính điểm oob trên validation data nên kém chính xác hơn. Tuy nhiên, pp này hiệu quả về mặt tính toán nếu sử dụng nhiều cây, hơn nữa còn show ra được các biến model đang coi là importance thay vì các biến kiểm tra từ tệp bên ngoài.</p></li>
</ul>
<p>gini decrease: <code class="docutils literal notranslate"><span class="pre">model.feature_importances_</span> </code></p>
<p><img alt="image.png" src="../../_images/de_gini_rf.png" /></p>
<p><strong>3. Tunning hyperparameter</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">nodesize</span></code>: tăng nodesize giảm overfitting</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code>:</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">maxnodes</span></code> = 2 * <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> - 1 = Số lượng node tối đa cho mỗi 1 decision tree</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_wine</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_wine</span><span class="p">(</span><span class="n">return_X_y</span> <span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rfc</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="c1"># The number of trees in the forest.</span>
    <span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="c1"># Function to measure quality of split {“gini”, “entropy”, “log_loss”}</span>
    <span class="n">max_depth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># max depth of single tree, higher is more overfitting </span>
    <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="c1"># Số sample tối thiểu cần có để tiếp tục thực hiện split, </span>
                            <span class="c1"># nếu sample ít hơn, thực hiện assign class bằng probability lớn hơn.</span>
    <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="c1"># Số sample tối thiểu của 1 leaf, sẽ không tạo ra các leaf có số sample trong leaf ít hơn</span>
    <span class="n">min_weight_fraction_leaf</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">max_features</span><span class="o">=</span><span class="s1">&#39;sqrt&#39;</span><span class="p">,</span> <span class="c1"># The number of features to consider when looking for the best split</span>
    <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># Số lượng node tối đa cho mỗi 1 decision tree</span>
    <span class="n">min_impurity_decrease</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">bootstrap</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">oob_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># use out-of-bag samples to estimate the generalization score</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">ccp_alpha</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># If bootstrap is True, the number of samples to draw from X to train each base estimator</span>
<span class="p">)</span>

<span class="n">rfc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">rfc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9555555555555556
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># oob score</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;oob score = &#39;</span><span class="p">,</span><span class="n">rfc</span><span class="o">.</span><span class="n">oob_score_</span><span class="p">)</span>

<span class="c1"># oob error</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;oob error = &#39;</span><span class="p">,</span><span class="mi">1</span> <span class="o">-</span> <span class="n">rfc</span><span class="o">.</span><span class="n">oob_score_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>oob score =  0.9699248120300752
oob error =  0.03007518796992481
</pre></div>
</div>
</div>
</div>
<p><strong>Feature importance based on mean decrease in impurity</strong></p>
<p>Warning: Impurity-based feature importances can be misleading for high cardinality features (many unique values)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">importances</span> <span class="o">=</span> <span class="n">rfc</span><span class="o">.</span><span class="n">feature_importances_</span>
<span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">([</span><span class="n">tree</span><span class="o">.</span><span class="n">feature_importances_</span> <span class="k">for</span> <span class="n">tree</span> <span class="ow">in</span> <span class="n">rfc</span><span class="o">.</span><span class="n">estimators_</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">forest_importances</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">importances</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">forest_importances</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">yerr</span><span class="o">=</span><span class="n">std</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Feature importances using MDI&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Mean decrease in impurity&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/d6044b6af13d8c34293fad9caae842388147d088a6d2acb7271278a759937400.png" src="../../_images/d6044b6af13d8c34293fad9caae842388147d088a6d2acb7271278a759937400.png" />
</div>
</div>
<p><strong>Feature importance based on feature permutation</strong></p>
<p>Permutation feature importance overcomes limitations of the impurity-based feature importance: they do not have a bias toward high-cardinality features and can be computed on a left-out test set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.inspection</span> <span class="kn">import</span> <span class="n">permutation_importance</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">permutation_importance</span><span class="p">(</span><span class="n">rfc</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">forest_importances</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">importances_mean</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">forest_importances</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">yerr</span><span class="o">=</span><span class="n">result</span><span class="o">.</span><span class="n">importances_std</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Feature importances using permutation on full model&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Mean accuracy decrease&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/158d97bb4e41c0477a95f5e3d0c21717000f9b500e32128a733f88056e64d519.png" src="../../_images/158d97bb4e41c0477a95f5e3d0c21717000f9b500e32128a733f88056e64d519.png" />
</div>
</div>
</section>
<section id="extremely-randomized-trees-extra-tree">
<h3><span class="section-number">1.8.2.2. </span>Extremely Randomized Trees (extra-tree)<a class="headerlink" href="#extremely-randomized-trees-extra-tree" title="Permalink to this heading">#</a></h3>
<p>Tương tự như random forest, khác ở điểm thay vì chọn ngưỡng tối ưu để split (cut-off split point) ở node như RF thì sẽ chọn ngẫu nhiên ở ET.</p>
<ul class="simple">
<li><p>Thuật toán chạy nhanh hơn so với RF, nên phù hợp với dữ liệu lớn hơn</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">ExtraTreesClassifier</span>
<span class="n">etc</span> <span class="o">=</span> <span class="n">ExtraTreesClassifier</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">etc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9555555555555556
</pre></div>
</div>
</div>
</div>
</section>
<section id="bagging-meta-estimator">
<h3><span class="section-number">1.8.2.3. </span>Bagging meta-estimator<a class="headerlink" href="#bagging-meta-estimator" title="Permalink to this heading">#</a></h3>
<p>Sử dụng estimator bất kỳ cho phương pháp bagging</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="n">bagging</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">KNeighborsClassifier</span><span class="p">(),</span>
                            <span class="n">max_samples</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="boosting">
<h2><span class="section-number">1.8.3. </span>Boosting<a class="headerlink" href="#boosting" title="Permalink to this heading">#</a></h2>
<p>Xây dựng các model cùng loại, mỗi model sau sẽ dự đoán error của model trước, tạo thành chuỗi model mà model sau sẽ tốt hơn model trước.</p>
<p>–&gt; Mục tiêu là giảm bias - áp dụng cho các model có variance thấp và bị bias cao</p>
<ul class="simple">
<li><p>Boosting là một quá trình tuần tự, không thể xử lí song song, do đó, thời gian train mô hình có thể tương đối lâu.</p></li>
<li><p>Sau mỗi vòng lặp, Boosting có khả năng làm giảm error theo cấp số nhân.</p></li>
<li><p>Boosting sẽ hoạt động tốt nếu base learner của nó không quá phức tạp cũng như error không thay đổi quá nhanh.</p></li>
<li><p>Boosting giúp làm giảm giá trị bias cho các model base learner.</p></li>
</ul>
<section id="adaboost">
<h3><span class="section-number">1.8.3.1. </span>AdaBoost<a class="headerlink" href="#adaboost" title="Permalink to this heading">#</a></h3>
<p>Thuật toán tổng hợp các submodel theo trọng số trên toàn bộ data với model sau được build trên data đã được re-weighting với idea trên model trước đó, data point nào gây ra error lớn thì có weight cao hơn và ngược lại.</p>
<p>Tuy nhiên với dữ liệu có large error (bias) thì Gradient Boosting hiệu quả hơn</p>
<ul class="simple">
<li><p>AdaBoost can be used both for classification and regression problems</p></li>
</ul>
<p><strong>Procedure</strong></p>
<ol class="arabic simple">
<li><p>Khởi tạo ban đầu với tham số</p></li>
</ol>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(M\)</span> là số lượng submodels,</p></li>
<li><p>weight của <span class="math notranslate nohighlight">\(N\)</span> data point ban đầu <span class="math notranslate nohighlight">\(w_0 =\frac{1}{N}\)</span>,</p></li>
<li><p>final model ban đầu <span class="math notranslate nohighlight">\(F_0\)</span> = 0.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Tại vòng lặp thứ i:</p></li>
</ol>
<ul class="simple">
<li><p>Train model <span class="math notranslate nohighlight">\(f_i\)</span> để lấy được <code class="docutils literal notranslate"><span class="pre">minimizes</span> <span class="pre">weighted</span> <span class="pre">error</span></code> <span class="math notranslate nohighlight">\(\epsilon_i\)</span> = tổng các trọng số <span class="math notranslate nohighlight">\(w_i\)</span> của các data point bị misclassified (dự đoán bị sai).</p></li>
<li><p>Tính trọng số <code class="docutils literal notranslate"><span class="pre">model_i</span></code> theo công thức: <span class="math notranslate nohighlight">\(\alpha_i = 0.5*\ln(\frac{1}{\epsilon_i} -1)\)</span></p></li>
<li><p>Cập nhật <span class="math notranslate nohighlight">\(w_{i+1}\)</span> cho <span class="math notranslate nohighlight">\(N\)</span> datapoint model tiếp theo:
<span class="math notranslate nohighlight">\(w_{i+1(n)} = w_i * e^{- y_n * \alpha_i * f_i(x_n)} \)</span> cho datapoint thứ n</p></li>
<li><p>Chuẩn hoá <span class="math notranslate nohighlight">\(w_{i+1}\)</span> bằng cách chia cho tổng <span class="math notranslate nohighlight">\(w_{i+1}\)</span> sao cho tổng của chúng = 1</p></li>
<li><p>Cập nhật final model: <span class="math notranslate nohighlight">\(F_i = F_{i-1} + \alpha_i * f_i\)</span></p></li>
<li><p>Output khi chạy model là <span class="math notranslate nohighlight">\(H = sign(F_M)\)</span></p></li>
</ul>
<p>FYI: AdaBoost có thể được áp dụng mà không cần dựa vào việc đánh trọng số lại các điểm dữ liệu, thay vào đó, chúng ta có thể re-sample để lấy dữ liệu train cho các model tiếp theo dựa vào xác suất được xác định bới các trọng số.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span>    
    <span class="n">estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># thuật toán kết hợp với pp adaboost, mặc định là decision tree</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="c1"># số lượng tối đa estimators sử dụng, nếu vượt quá thì ko quá trình boosting nữa</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="c1"># hệ số learning rate</span>
<span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8666666666666667
</pre></div>
</div>
</div>
</div>
</section>
<section id="gradient-boosting">
<h3><span class="section-number">1.8.3.2. </span>Gradient Boosting<a class="headerlink" href="#gradient-boosting" title="Permalink to this heading">#</a></h3>
<p>Tương tự như cách hoạt động của adaboost, thay vì cập nhật weight các features thì gradient boosting cập nhật <code class="docutils literal notranslate"><span class="pre">model</span> <span class="pre">mới</span></code> = <code class="docutils literal notranslate"><span class="pre">model</span> <span class="pre">cũ</span></code> + <code class="docutils literal notranslate"><span class="pre">pseudo-residuals</span></code></p>
<p>Model tiếp theo sẽ fit vào <code class="docutils literal notranslate"><span class="pre">pseudo-residuals</span></code> của model trước đó
<span class="math notranslate nohighlight">\(M_{n}=M_{n-1}-\eta{\frac{\partial}{\partial m}}L(M_{n-1})\)</span></p>
</section>
<section id="xgboost">
<h3><span class="section-number">1.8.3.3. </span>XGBoost<a class="headerlink" href="#xgboost" title="Permalink to this heading">#</a></h3>
<p>Base trên gradient boosting nhưng cải tiến về mặt thuật toán, kết hợp cả GPU và CPU</p>
<ul class="simple">
<li><p>XGBoost có thể được sử dụng để giải quyết được tất cả các vấn đề từ hồi quy (regression), phân loại (classification), ranking và giải quyết các vấn đề do người dùng tự định nghĩa.</p></li>
<li><p>Engineering để tránh overfitting như: sub-sampling row, column, column per split levels, áp dụng regularized L1 và L2.</p></li>
<li><p>Khả năng tận dụng tài nguyên hệ thống: tính toán song song trên CPU/GPU, tính toán phân tán trên nhiều server, tính toán khi tài nguyên bị giới hạn, cache optimization để tăng tốc training.</p></li>
<li><p>Và cuối cùng là khả năng xử lý missing data value, tiếp tục training bằng mô hình đã được build trước đó để tiết kiệm thời gian.</p></li>
</ul>
<p><strong>1. Avoid overfitting</strong>
Overfitting in XGB có thể dẫn tới predict dữ liệu chưa có trong tập train có thể giảm độ chính xác và kết quả dự đoán có high variance, unstable. Các pp giảm overfitting:</p>
<ul class="simple">
<li><p><strong>Cross-validation</strong></p></li>
<li><p><strong>Regularization</strong>: Sử dụng penalty (L1 hoặc L2) cho cost function. Increasing <code class="docutils literal notranslate"><span class="pre">alpha</span></code> or <code class="docutils literal notranslate"><span class="pre">lambda</span></code> will penalize more complex models and reduce the size of trees that are fit</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">reg_alpha</span></code> : Manhattan distance (L1 regu)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">reg_lambda</span></code> : squared Euclidean dítance (L2 regu)</p></li>
</ul>
</li>
<li><p><strong>Early stopping</strong>:</p></li>
<li><p><strong>Reduce number of trees</strong>:</p></li>
<li><p><strong>Reduce number of features selection</strong>:</p></li>
</ul>
<p><strong>2. Hyperparameters</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">eta/learning_rate</span></code>: the alpha in The Boosting Algorithm, if the data has more noisy, reduce the <code class="docutils literal notranslate"><span class="pre">lr</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_depth</span></code>: the maximum depth of leaf, lower maxdepth helps reduce overfitting</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">nrounds/n_estimators</span></code>: số lượng tối đa estimators sử dụng (boosting rounds). Nếu lr thấp, nên set n_estimators cao do quá trình học chậm, update ít.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">subsample</span></code>: tỷ lệ %rawsample without replacement cho mỗi 1 round model, để thấp tránh được overfitting</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">colsample_bytree</span></code>: tỷ lệ %features use for each round model, để thấp tránh được overfitting, hỗ trợ cho TH input predict bị thiếu feature</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lambda/reg_lambda</span></code> and <code class="docutils literal notranslate"><span class="pre">alpha/reg_alpha</span></code>: Hệ số alpha (Lasso - L1) và lambda (Ridge-L2) cho regularization</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span><span class="p">,</span> <span class="n">StratifiedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">(</span><span class="n">return_X_y</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">as_frame</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">eval_set</span> <span class="o">=</span> <span class="p">[(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)]</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s2">&quot;objective&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;binary:logistic&quot;</span><span class="p">],</span> 
  <span class="s2">&quot;booster&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;gbtree&quot;</span><span class="p">],</span> 
  <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span> <span class="p">]</span> <span class="p">,</span> <span class="c1">#[3, 5, 7], # default: 3 only for depthwise</span>
  <span class="s2">&quot;n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">]</span> <span class="p">,</span> <span class="c1"># [500, 1000], # default: 500  </span>
  <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.05</span> <span class="p">]</span> <span class="p">,</span> <span class="c1"># [0.1, 0.05, 0.01], # default: 0.05 </span>
  <span class="s2">&quot;subsample&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.6</span><span class="p">]</span> <span class="p">,</span> <span class="c1">#  [0.6, 0.8], </span>
  <span class="s2">&quot;colsample_bytree&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.6</span><span class="p">]</span> <span class="p">,</span> <span class="c1">#  [0.6, 0.8],</span>
  <span class="s2">&quot;colsample_bylevel&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.6</span><span class="p">]</span> <span class="p">,</span> <span class="c1">#  [0.6, 0.8],</span>
  <span class="s2">&quot;random_state&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span>
  <span class="s1">&#39;min_child_weight&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">11</span><span class="p">],</span> 
  <span class="s2">&quot;eval_metric&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;auc&quot;</span><span class="p">],</span> 
<span class="p">}</span>
<span class="n">cv</span><span class="o">=</span><span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">xgb_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">()</span>

<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">xgb_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                        <span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">grid_result</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="n">eval_set</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Score: &quot;</span><span class="p">,</span> <span class="n">grid_result</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 4 folds for each of 1 candidates, totalling 4 fits
Best Score:  0.9807611853320808
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default plot_importance</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">plot_importance</span>
<span class="n">plot_importance</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/f6bd62b8410ff3f74b7a09ca16cc8c91443375e547a8d1b4535ae7fdc93ba5cb.png" src="../../_images/f6bd62b8410ff3f74b7a09ca16cc8c91443375e547a8d1b4535ae7fdc93ba5cb.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># evaluation plot</span>
<span class="c1"># retrieve performance metrics </span>
<span class="n">results</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">evals_result</span><span class="p">()</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;validation_0&#39;</span> <span class="p">][</span><span class="s1">&#39;auc&#39;</span><span class="p">])</span>
<span class="n">x_axis</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">epochs</span><span class="p">)</span>
 
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_axis</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;validation_0&#39;</span><span class="p">][</span><span class="s1">&#39;auc&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_axis</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;validation_1&#39;</span><span class="p">][</span><span class="s1">&#39;auc&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Test&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;AUC&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;XGBoost AUC&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/81a348510c2fe2b08fe2098fbcc248c4f005f2c05413292bdd15144a5ad49cd9.png" src="../../_images/81a348510c2fe2b08fe2098fbcc248c4f005f2c05413292bdd15144a5ad49cd9.png" />
</div>
</div>
</section>
<section id="lightgbm">
<h3><span class="section-number">1.8.3.4. </span>LightGBM<a class="headerlink" href="#lightgbm" title="Permalink to this heading">#</a></h3>
<p><strong>LightGBM</strong> sử dụng “histogram-based algorithms” thay thế cho “pre-sort-based algorithms ” thường được dùng trong các boosting tool khác để tìm kiếm split point trong quá trình xây dựng tree. Cải tiến này giúp LightGBM tăng tốc độ training, đồng thời làm giảm bộ nhớ cần sử dụng. Cả xgboost và lightgbm đều sử dụng histogram-based algorithms, điểm tối ưu của lightgbm so với xgboost là ở 2 thuật toán: GOSS (Gradient Based One Side Sampling) và EFB (Exclusive Feature Bundling) giúp tăng tốc đáng kể trong quá trình tính toán. Chi tiết về GOSS và EFB, các bạn có thể đọc thêm tại: <a class="reference external" href="https://towardsdatascience.com/what-makes-lightgbm-lightning-fast-a27cf0d9785e">https://towardsdatascience.com/what-makes-lightgbm-lightning-fast-a27cf0d9785e</a></p>
<p><strong>LightGBM</strong> phát triển tree dựa trên <strong>leaf-wise</strong>, trong khi hầu hết các boosting tool khác (kể cả <code class="docutils literal notranslate"><span class="pre">xgboost</span></code>) dựa trên <strong>level-wise</strong>.</p>
<ul class="simple">
<li><p><strong>Leaf-wise</strong> phát triển tree theo node đang xét cho hết node đó rồi mới nhảy sang node tiếp theo ==&gt; nên sử dụng <code class="docutils literal notranslate"><span class="pre">maxdepth</span></code> để tránh overfitting.</p></li>
<li><p><strong>Leaf-wise</strong> lựa chọn nút để phát triển cây dựa trên tối ưu toàn bộ tree, trong khi <strong>level-wise</strong> tối ưu trên nhánh đang xét (<strong>level-wise</strong>: phát triển theo tầng của tree, khi phát triển hết tầng thì mới nhảy xuống tầng tiếp theo.), do đó, với số node nhỏ, các tree xây dựng từ <strong>leaf-wise</strong> thường out-perform <strong>level-wise</strong>.</p></li>
</ul>
<p>Note: Leaf-wise tuy tốt, nhưng với những bộ dữ liệu nhỏ, các tree xây dựng dựa trên leaf-wise thường dẫn đến overfit khá sớm. Do đó, lightgbm sử dụng thêm 1 hyperparameter là maxdepth nhằm cố gắng hạn chế điều này. Dù vậy, LightGBM vẫn được khuyến khích sử dụng khi bộ dữ liệu là đủ to.</p>
<p><strong>Lựa chọn LightGBM thay cho XGBoost</strong>:</p>
<ul class="simple">
<li><p>Dữ liệu lớn</p></li>
<li><p>Nhiều categorical features</p></li>
<li><p>Ưu tiên tốc độ hơn performance model</p></li>
<li><p>Khắc phục vấn đề training lâu cho dữ liệu lớn của XGboost</p></li>
</ul>
</section>
</section>
<section id="stacking">
<h2><span class="section-number">1.8.4. </span>Stacking<a class="headerlink" href="#stacking" title="Permalink to this heading">#</a></h2>
<p>Xây dựng các base-model khác loại train trên cùng 1 bộ dữ liệu tạo thành 1 meta model, train các model này độc lập sau đó sẽ tìm cách kết hợp/ hoặc xây dựng 1 metamodel để predict output từ input là output của các base-model</p>
<p>–&gt; Mục tiêu là giảm bias - áp dụng cho các model có variance thấp và bị bias cao</p>
<p><strong>1. Level-model</strong></p>
<ul class="simple">
<li><p><strong>Level 0 (base model)</strong>: Mô hình cơ sở học trực tiếp từ bộ dữ liệu và đưa ra dự đoán cho mô hình level-1</p>
<ul>
<li><p>Các base-models có những cách học khác nhau trên bộ dữ liệu, cho nên outputs hay errors của các base-models là không tương quan (uncorrelated) hay có độ tương quan thấp (low correlation).</p></li>
<li><p>Đầu ra của base-models có thể là giá trị thực (cho bài toán Hồi quy) hoặc là các xác suất của nhãn trong bài toán phân loại.</p></li>
<li><p>Base-models thường phức tạp và đa dạng, mỗi mô hình có cách học và giải quyết vấn đề khác nhau với cùng một bài toán như: Decision Tree, SVM, Neural Network,… và kể cả là các thuật toán ensemble khác như GBM, Random Forest,…</p></li>
</ul>
</li>
<li><p><strong>Level 1 (meta model)</strong>:Mô hình học từ các dự đoán của mô hình cơ sở (level-0) hoặc có thể kết hợp thêm input của base model, Meta-model thường đơn giản:</p>
<ul>
<li><p>Linear Regression cho bài toán Regression -&gt; Trả về số thực</p></li>
<li><p>Logistic Regression cho bài toán Classification -&gt; Trả về xác suất các label</p></li>
</ul>
</li>
</ul>
<p><strong>Thuật toán stacking</strong></p>
<ul class="simple">
<li><p>Khởi tạo ban đầu:</p>
<ul>
<li><p>Dataset = Train + Test</p></li>
<li><p>Train = k-fold</p></li>
<li><p>Set base-models (M) - level 0</p></li>
<li><p>Strong-model (H) - level 1</p></li>
</ul>
</li>
<li><p>Với mỗi base-model (m) trong set base-models (M):</p>
<ul>
<li><p>Với mỗi fold, train model m trong k-1 fold còn lại và predict fold đó. Sau k vong lặp, thu được k-fold predicted từ k model (cùng 1 base-model) mà kết quả predict này không xuất hiện để train model (tránh được overfitting).  k-fold predicted này sẽ sử dụng làm 1 feature trong train-dataset cho model H.</p></li>
<li><p>Lấy toàn bộ dữ liệu trong train data để train model thứ k+1 (cùng base-model) và predict test data, kết quả thu được làm 1 feature trong test-dataset cho model H</p></li>
</ul>
</li>
<li><p>Lặp lại với các M-1 base model khác thu được tổng cộng M feature của train và M feature của test dataset cho model H</p></li>
</ul>
<p>Một số biến thể trong cách triển khai:</p>
<ul class="simple">
<li><p>Kết hợp 1 số features của base-model + predicted base-model = tranining dataset của meta-model</p></li>
<li><p>Thay vì sử dụng toàn bộ train dataset để build base-model thứ k+1 và predict test dataset thì sử dụng k-model từ k-fold để predict luôn test dataset, thu được k bộ dự đoán về test dataset. Phương pháp tổng hợp kết quả của k bộ dự đoán test dataset là nếu bài toán regression thì dùng mean, Nếu bài toán Classification thì cùng max-voting</p></li>
<li><p>Multi-levels Stacking: Tăng thành 3 level model, tuy nhiên không sử dụng k-fold, thì số lượng dữ liệu cần dùng là rất nhiều, vì hiện tượng overfitting rất dễ xảy ra, nhưng nếu sử dụng k-fold, thì thời gian huấn luyện là cực kì tốn kém.</p></li>
</ul>
<p><strong>Stacking family</strong>
<em><strong>1. Voting ensemble</strong></em></p>
<p>Thay vì sử dụng 1 meta-model (level 1) thì sử dụng các phương pháp lựa chọn output đơn giản hơn:</p>
<ul class="simple">
<li><p>Trong bài toán Regression, Voting đưa ra mean hoặc median của các predictions từ các base-models</p></li>
<li><p>Trong bài toán Classification, Voting sẽ sử dụng Hard-voting (Class được predicted nhiều nhất) hoặc Soft-voting (Class có tổng xác suất được predicted là cao nhất)
Trong Voting, tất cả các base-models được giả định có cùng độ quan trọng như nhau, cùng hiệu năng như nhau,</p></li>
</ul>
<p><em><strong>2. Weighted Average Ensemble</strong></em></p>
<p>Điều chỉnh Voting ensemble bằng việc thêm weighted cho base-model dựa trên độ chính xác hoặc tự build 1 process để tối ưu trọng số</p>
<p><em><strong>3. Blending Ensemble</strong></em></p>
<p>Thay đổi stacking bằng cách thay vì sử dụng cross-validation ở training set thì chia training set thành <code class="docutils literal notranslate"><span class="pre">train</span> <span class="pre">set</span></code> + <code class="docutils literal notranslate"><span class="pre">validation</span> <span class="pre">set</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Trainset</span></code> dùng để train base model, sau đó predict tại <code class="docutils literal notranslate"><span class="pre">validationset</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Validationset</span></code> + prediction <code class="docutils literal notranslate"><span class="pre">validationset</span></code> (base-model) sẽ làm input (<strong>set1</strong>) cho meta-model</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Test</span> <span class="pre">set</span></code> và các kết quả dự đoán trên <code class="docutils literal notranslate"><span class="pre">test</span> <span class="pre">set</span></code> của các base models được sử dụng như là <code class="docutils literal notranslate"><span class="pre">test</span> <span class="pre">set</span></code> (<strong>set2</strong>) của blending model.</p></li>
<li><p>Train và đánh giá blending model sử dụng <strong>set1</strong> và <strong>set2</strong>.</p></li>
</ul>
<p><em><strong>4. Super Learner Ensemble</strong></em></p>
<p><img alt="image.png" src="../../_images/SuperLearnerEnsemble.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeCV</span><span class="p">,</span> <span class="n">LassoCV</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">StackingRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># load data</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="o">*</span><span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

<span class="c1"># setup base model (level 0)</span>
<span class="n">estimators</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;ridge&#39;</span><span class="p">,</span> <span class="n">RidgeCV</span><span class="p">()),</span>
              <span class="p">(</span><span class="s1">&#39;lasso&#39;</span><span class="p">,</span> <span class="n">LassoCV</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)),</span>
              <span class="p">(</span><span class="s1">&#39;knr&#39;</span><span class="p">,</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                                          <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">))]</span>

<span class="c1"># setup meta model (level1)</span>
<span class="c1"># The final_estimator will use the predictions of the estimators as input</span>
<span class="n">final_estimator</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> 
                                            <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">1</span><span class="p">,)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">StackingRegressor</span><span class="p">(</span><span class="n">estimators</span><span class="p">,</span> <span class="n">final_estimator</span><span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.42738455065984304
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># multi layer stacking</span>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="n">multi_layer_regressor</span> <span class="o">=</span> <span class="n">StackingRegressor</span><span class="p">(</span>
    <span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;ridge&#39;</span><span class="p">,</span> <span class="n">RidgeCV</span><span class="p">()),</span>
                <span class="p">(</span><span class="s1">&#39;lasso&#39;</span><span class="p">,</span> <span class="n">LassoCV</span><span class="p">()),</span>
                <span class="p">(</span><span class="s1">&#39;knr&#39;</span><span class="p">,</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                                            <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">))],</span>
    <span class="n">final_estimator</span><span class="o">=</span><span class="n">StackingRegressor</span><span class="p">(</span>
        <span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">2</span><span class="p">)),</span>
                    <span class="p">(</span><span class="s1">&#39;gbrt&#39;</span><span class="p">,</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">2</span><span class="p">))],</span>
        <span class="n">final_estimator</span><span class="o">=</span><span class="n">RidgeCV</span><span class="p">()</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">multi_layer_regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">multi_layer_regressor</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.41430511335119347
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./1_Process_Modelling\Split_notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="4_ML_Supervised_learning_Algorithms-6.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">1.7. </span>Tree-base model</p>
      </div>
    </a>
    <a class="right-next"
       href="4_ML_Supervised_learning_Algorithms-8.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">1.9. </span>Multi-class and multi-output</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#weighted">1.8.1. Weighted</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bagging">1.8.2. Bagging</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest">1.8.2.1. Random Forest</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#extremely-randomized-trees-extra-tree">1.8.2.2. Extremely Randomized Trees (extra-tree)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bagging-meta-estimator">1.8.2.3. Bagging meta-estimator</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#boosting">1.8.3. Boosting</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adaboost">1.8.3.1. AdaBoost</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-boosting">1.8.3.2. Gradient Boosting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#xgboost">1.8.3.3. XGBoost</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lightgbm">1.8.3.4. LightGBM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stacking">1.8.4. Stacking</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Khổng Tiến Đạt
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>