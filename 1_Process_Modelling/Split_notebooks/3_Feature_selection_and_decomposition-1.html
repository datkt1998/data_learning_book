

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>4.1. Filter methods &#8212; Machine Learning book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '1_Process_Modelling/Split_notebooks/3_Feature_selection_and_decomposition-1';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="4.2. Wrapped methods" href="3_Feature_selection_and_decomposition-2.html" />
    <link rel="prev" title="4. Overview of feature selection" href="0_toc_fs.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../_jupyter_book_files/intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../_jupyter_book_files/intro.html">
                    Welcome to Dat’s Notebook
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Process Modeling</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="0_toc_eda.html">1. Statistic and EDA</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="1_Statistics_and_EDA-0.html">1.1. Data Analyst Process</a></li>
<li class="toctree-l2"><a class="reference internal" href="1_Statistics_and_EDA-1.html">1.2. Read datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="1_Statistics_and_EDA-2.html">1.3. Explore data analysis (EDA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="1_Statistics_and_EDA-3.html">1.4. Description statistic</a></li>
<li class="toctree-l2"><a class="reference internal" href="1_Statistics_and_EDA-4.html">1.5. Inferential statistic</a></li>
<li class="toctree-l2"><a class="reference internal" href="1_Statistics_and_EDA-5.html">1.6. Kiểm định giả thuyết (Hypothesis testing)</a></li>
<li class="toctree-l2"><a class="reference internal" href="1_Statistics_and_EDA-6.html">1.7. ANOVA</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="0_toc_fe.html">2. Feature Engineering</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="2_Feature_engineering-1.html">2.1. Custom Transforms Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_Feature_engineering-2.html">2.2. Feature extraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_Feature_engineering-3.html">2.3. Variable Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_Feature_engineering-4.html">2.4. Missing Imputation</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_Feature_engineering-5.html">2.5. Categorical Encoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_Feature_engineering-6.html">2.6. Feature transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_Feature_engineering-7.html">2.7. Discretisation</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_Feature_engineering-8.html">2.8. Outliers</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_Feature_engineering-9.html">2.9. Feature scaling</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_Feature_engineering-10.html">2.10. Feature selection</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="0_toc_imb.html">3. Imbalance Dataset Handling</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="3_Imbalance_data_handling-1.html">3.1. Data-level approaches</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_Imbalance_data_handling-2.html">3.2. Cost sensitive approaches</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_Imbalance_data_handling-3.html">3.3. Ensemble approaches</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_Imbalance_data_handling-4.html">3.4. Ensemble approaches</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="0_toc_fs.html">4. Feature Selection</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">4.1. Filter methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_Feature_selection_and_decomposition-2.html">4.2. Wrapped methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_Feature_selection_and_decomposition-3.html">4.3. Embedded methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_Feature_selection_and_decomposition-4.html">4.4. Hybrid methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_Feature_selection_and_decomposition-5.html">4.5. Feature decomposition</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="0_toc_eva.html">5. Evaluation Metrics</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="5_Evaluation_metrics-0.html">5.1. Define scorer</a></li>
<li class="toctree-l2"><a class="reference internal" href="5_Evaluation_metrics-1.html">5.2. Classification metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="5_Evaluation_metrics-2.html">5.3. Regression metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="5_Evaluation_metrics-3.html">5.4. Clustering metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="5_Evaluation_metrics-4.html">5.5. Pairwise metrics</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="6_Models_monitoring_production-0.html">6. Model Monitoring</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="6_Models_monitoring_production-1.html">6.7. Functional level monitoring</a></li>
<li class="toctree-l2"><a class="reference internal" href="6_Models_monitoring_production-2.html">6.8. Operational level monitoring</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ML/DL Algorithms</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="0_toc_ml_su.html">1. ML Supervised Learning</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Supervised_learning_Algorithms-0.html">1.1. Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Supervised_learning_Algorithms-1.html">1.2. Naive Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Supervised_learning_Algorithms-2.html">1.3. Discriminant Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Supervised_learning_Algorithms-3.html">1.4. Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Supervised_learning_Algorithms-4.html">1.5. Support Vector Machines (SVM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Supervised_learning_Algorithms-5.html">1.6. Nearest neighbors</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Supervised_learning_Algorithms-6.html">1.7. Tree-base model</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Supervised_learning_Algorithms-7.html">1.8. Ensemble learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Supervised_learning_Algorithms-8.html">1.9. Multi-class and multi-output</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Supervised_learning_Algorithms-9.html">1.10. Neural network models</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="0_toc_ml_unsu.html">2. ML Unsupervised Learning</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Unsupervised_learning_Algorithms-0.html">2.1. Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Unsupervised_learning_Algorithms-1.html">2.2. Decomposing components</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Unsupervised_learning_Algorithms-2.html">2.3. Manifold learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Unsupervised_learning_Algorithms-3.html">2.4. Novelty and Outlier Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_ML_Unsupervised_learning_Algorithms-4.html">2.5. Neural network</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="0_toc_dl.html">3. Deep Learning</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="4_DL_Algorithms-0.html">3.1. Neural Network</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">My Modules</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../3_Mathematics/0_toc.html">1. Mathematics</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../3_Mathematics/1_Linear_algebra.html">1.1. Linear algebra</a></li>



<li class="toctree-l2"><a class="reference internal" href="../../3_Mathematics/2_Calculus_and_optimization.html">1.5. Calculus and optimization</a></li>






<li class="toctree-l2"><a class="reference internal" href="../../3_Mathematics/3_Distribution_and_statistic.html">1.12. Distribution and statistics</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../3_Mathematics/4_Information_theory.html">1.14. Information theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../3_Mathematics/5_Graph_theory.html">1.15. Graph theory</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../4_Programming/0_toc.html">2. Programming</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../4_Programming/1_SQL.html">2.1. SQL</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../4_Programming/2_noSQL.html">2.2. noSQL</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../4_Programming/3_pySpark.html">2.3. pySpark</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../4_Programming/4_Python.html">2.4. Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../4_Programming/6_Git.html">2.5. Git</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../4_Programming/7_Docker.html">2.6. Docker</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../2_My_Modules/0_toc.html">3. My Functions</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../2_My_Modules/1_Data_Cleaning.html">3.1. Data Cleaning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../2_My_Modules/2_Connection.html">3.2. Connection</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../6_Tools_and_Projects/0_toc.html">4. Tools and Projects</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../6_Tools_and_Projects/deploy_callAPI_model_in_GCP.html">4.1. Deploy model on GCP and call API streamlit</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/datkt1998/DS_learning_book" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/1_Process_Modelling/Split_notebooks/3_Feature_selection_and_decomposition-1.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Filter methods</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#constant-features">4.1.1. Constant features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quasi-constant-features">4.1.2. Quasi-constant features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#duplicated-features">4.1.3. Duplicated features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-features">4.1.4. Correlation features</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#brute-force-approach">4.1.4.1. brute force approach</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#highly-corr-group-approach">4.1.4.2. highly corr group approach</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-with-feature-engine">4.1.4.3. Correlation with Feature-engine</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#dropcorrelatedfeatures">4.1.4.3.1. DropCorrelatedFeatures</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#smartcorrelationselection-by-performance">4.1.4.3.2. SmartCorrelationSelection by Performance</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#smartcorrelationselection-by-variance">4.1.4.3.3. SmartCorrelationSelection by Variance</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pipeline">4.1.4.3.4. pipeline</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistic-test">4.1.5. Statistic test</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mutual-information">4.1.5.1. Mutual information</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#chi-square-test">4.1.5.2. Chi-square test</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#univariate-selection-anova">4.1.5.3. Univariate selection (anova)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#univariate-with-model-performance">4.1.6. Univariate with model performance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#target-mean-encoding-selection">4.1.7. Target mean encoding selection</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="filter-methods">
<h1><span class="section-number">4.1. </span>Filter methods<a class="headerlink" href="#filter-methods" title="Permalink to this heading">#</a></h1>
<ul class="simple">
<li><p>Rely on the feature characteristics, not use ML algorithms.</p></li>
</ul>
<p><strong>1. Advantages</strong>:</p>
<ul class="simple">
<li><p>The selected subset can be used for any ML models</p></li>
<li><p>Less computationally expensive</p></li>
</ul>
<p><strong>2. Disavantages</strong>:</p>
<ul class="simple">
<li><p>Lower prediction performance than other methods.</p></li>
<li><p>Do not score the effect of subset to the model algorithms</p></li>
<li><p>May choose redudant variables because do not consider the relationships between features</p></li>
<li><p>Ignore some features that may be not predictive individually, but they have in combination with others</p></li>
</ul>
<p><strong>3. Usage</strong>:</p>
<ul class="simple">
<li><p><strong>Provide quick screen and fast remove the irrelevant features</strong></p></li>
<li><p><strong>The first filter step in feature selection</strong></p></li>
</ul>
<p><strong>4. Produce steps</strong>:</p>
<ul class="simple">
<li><p>Rank features according to a certain criteria (test), independently of feature space</p></li>
<li><p>Choose highest rank features</p></li>
</ul>
<p><strong>5. Rank Criteria</strong>:</p>
<ul class="simple">
<li><p>Basis</p>
<ul>
<li><p>Constanst</p></li>
<li><p>Quasi - constanst</p></li>
</ul>
</li>
<li><p>Statistics measures</p>
<ul>
<li><p>Fisher score, Chi-square test</p></li>
<li><p>Univariate methods (anova)</p></li>
<li><p>Mutual information</p></li>
</ul>
</li>
<li><p>Multivariate:</p>
<ul>
<li><p>Handle the redudant features</p></li>
<li><p>Duplicated features</p></li>
<li><p>Correlated features</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># load dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;Datasets/dataset_1.csv&#39;</span><span class="p">)</span>

<span class="c1"># separate dataset into train and test</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>  <span class="c1"># drop the target</span>
    <span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">],</span>  <span class="c1"># just the target</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((35000, 300), (15000, 300))
</pre></div>
</div>
</div>
</div>
<section id="constant-features">
<h2><span class="section-number">4.1.1. </span>Constant features<a class="headerlink" href="#constant-features" title="Permalink to this heading">#</a></h2>
<p>Constant features are those that show the same value, just one value, for all the observations of the dataset. In other words, the same value for all the rows of the dataset. These features provide no information that allows a machine learning model to discriminate or predict a target.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">VarianceThreshold</span>

<span class="c1"># If using the VarianceThreshold, all our variables need to be numerical</span>
<span class="n">sel</span> <span class="o">=</span> <span class="n">VarianceThreshold</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># remove all features that have their variances do not meet a certain threshold</span>

<span class="n">sel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>  <span class="c1"># fit finds the features with zero variance</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>VarianceThreshold(threshold=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">VarianceThreshold</label><div class="sk-toggleable__content"><pre>VarianceThreshold(threshold=0)</pre></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># get_support is a boolean vector that indicates which features are retained</span>
<span class="c1"># if we sum over get_support, we get the number of features that are not constant</span>

<span class="nb">sum</span><span class="p">(</span><span class="n">sel</span><span class="o">.</span><span class="n">get_support</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>266
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="o">~</span><span class="n">sel</span><span class="o">.</span><span class="n">get_support</span><span class="p">()]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>var_23</th>
      <th>var_33</th>
      <th>var_44</th>
      <th>var_61</th>
      <th>var_80</th>
      <th>var_81</th>
      <th>var_87</th>
      <th>var_89</th>
      <th>var_92</th>
      <th>var_97</th>
      <th>...</th>
      <th>var_195</th>
      <th>var_196</th>
      <th>var_201</th>
      <th>var_212</th>
      <th>var_215</th>
      <th>var_225</th>
      <th>var_227</th>
      <th>var_248</th>
      <th>var_294</th>
      <th>var_297</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>17967</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>32391</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>9341</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7929</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>46544</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 34 columns</p>
</div></div></div>
</div>
</section>
<section id="quasi-constant-features">
<h2><span class="section-number">4.1.2. </span>Quasi-constant features<a class="headerlink" href="#quasi-constant-features" title="Permalink to this heading">#</a></h2>
<p>Quasi-constant features are those that show the same value for the great majority of the observations of the dataset. In general, these features provide little, if any, information that allows a machine learning model to discriminate or predict a target. But there can be exceptions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">VarianceThreshold</span>

<span class="c1"># If using the VarianceThreshold, all our variables need to be numerical</span>
<span class="n">sel</span> <span class="o">=</span> <span class="n">VarianceThreshold</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span> <span class="c1"># remove all features that have their variances do not meet a certain threshold</span>

<span class="n">sel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># transform</span>
<span class="n">X_train_sl</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_sl</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_train_sl</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(35000, 300) (35000, 210)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># code manually for both categorical and numeric variables (VarianceThreshold just use for numeric)</span>
<span class="k">def</span> <span class="nf">get_quasi_constant_feat</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">dom_thold</span> <span class="o">=</span> <span class="mf">0.98</span><span class="p">):</span>
    <span class="c1"># create an empty list</span>
    <span class="n">quasi_constant_feat</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># iterate over every feature</span>
    <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>

        <span class="c1"># find the predominant value, that is the value that is shared</span>
        <span class="c1"># by most observations</span>
        <span class="n">predominant</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span>
            <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># evaluate the predominant feature: do more than 99% of the observations</span>
        <span class="c1"># show 1 value?</span>
        <span class="k">if</span> <span class="n">predominant</span> <span class="o">&gt;</span> <span class="n">dom_thold</span><span class="p">:</span>

            <span class="c1"># if yes, add the variable to the list</span>
            <span class="n">quasi_constant_feat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feature</span><span class="p">)</span>
            
    <span class="k">return</span> <span class="n">quasi_constant_feat</span>

<span class="n">quasi_constant_feat</span> <span class="o">=</span> <span class="n">get_quasi_constant_feat</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">quasi_constant_feat</span><span class="p">))</span> <span class="c1"># number of variables that each would be dominated above 98% by 1 value.</span>

<span class="c1"># finally, let&#39;s drop the quasi-constant features:</span>
<span class="n">X_train_sl</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">quasi_constant_feat</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X_test_sl</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">quasi_constant_feat</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_train_sl</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>186
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((35000, 300), (35000, 114))
</pre></div>
</div>
</div>
</div>
</section>
<section id="duplicated-features">
<h2><span class="section-number">4.1.3. </span>Duplicated features<a class="headerlink" href="#duplicated-features" title="Permalink to this heading">#</a></h2>
<p>we may often introduce duplicated features when performing one hot encoding of categorical variables, particularly if our datasets have many and /or highly cardinal categorical variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">feature_engine.selection</span> <span class="kn">import</span> <span class="n">DropDuplicateFeatures</span>

<span class="c1"># set up the selector</span>
<span class="n">sel</span> <span class="o">=</span> <span class="n">DropDuplicateFeatures</span><span class="p">(</span><span class="n">variables</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">missing_values</span><span class="o">=</span><span class="s1">&#39;raise&#39;</span><span class="p">)</span>

<span class="c1"># find the duplicate features, this might take a while</span>
<span class="n">sel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># set dup features</span>
<span class="n">sel</span><span class="o">.</span><span class="n">duplicated_feature_sets_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[{&#39;var_151&#39;, &#39;var_6&#39;},
 {&#39;var_116&#39;, &#39;var_7&#39;},
 {&#39;var_112&#39;,
  &#39;var_113&#39;,
  &#39;var_120&#39;,
  &#39;var_122&#39;,
  &#39;var_127&#39;,
  &#39;var_135&#39;,
  &#39;var_158&#39;,
  &#39;var_167&#39;,
  &#39;var_170&#39;,
  &#39;var_171&#39;,
  &#39;var_182&#39;,
  &#39;var_195&#39;,
  &#39;var_196&#39;,
  &#39;var_201&#39;,
  &#39;var_212&#39;,
  &#39;var_215&#39;,
  &#39;var_225&#39;,
  &#39;var_23&#39;,
  &#39;var_248&#39;,
  &#39;var_294&#39;,
  &#39;var_297&#39;,
  &#39;var_33&#39;,
  &#39;var_44&#39;,
  &#39;var_61&#39;,
  &#39;var_80&#39;,
  &#39;var_81&#39;,
  &#39;var_87&#39;,
  &#39;var_92&#39;,
  &#39;var_97&#39;,
  &#39;var_99&#39;},
 {&#39;var_183&#39;, &#39;var_34&#39;},
 {&#39;var_104&#39;, &#39;var_36&#39;},
 {&#39;var_148&#39;, &#39;var_37&#39;},
 {&#39;var_106&#39;, &#39;var_43&#39;},
 {&#39;var_216&#39;, &#39;var_60&#39;},
 {&#39;var_66&#39;, &#39;var_69&#39;},
 {&#39;var_287&#39;, &#39;var_67&#39;},
 {&#39;var_289&#39;, &#39;var_71&#39;},
 {&#39;var_199&#39;, &#39;var_84&#39;},
 {&#39;var_178&#39;, &#39;var_180&#39;, &#39;var_227&#39;, &#39;var_89&#39;},
 {&#39;var_133&#39;, &#39;var_223&#39;},
 {&#39;var_143&#39;, &#39;var_296&#39;},
 {&#39;var_149&#39;, &#39;var_239&#39;},
 {&#39;var_177&#39;, &#39;var_250&#39;},
 {&#39;var_187&#39;, &#39;var_285&#39;},
 {&#39;var_221&#39;, &#39;var_263&#39;},
 {&#39;var_226&#39;, &#39;var_232&#39;},
 {&#39;var_229&#39;, &#39;var_269&#39;}]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># in pipeline</span>
<span class="c1"># need to remove constant features first</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">VarianceThreshold</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;duplicated&#39;</span><span class="p">,</span> <span class="n">DropDuplicateFeatures</span><span class="p">()),</span>
<span class="p">])</span>

<span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[(&#x27;constant&#x27;, VarianceThreshold(threshold=0.02)),
                (&#x27;duplicated&#x27;, DropDuplicateFeatures())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" ><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[(&#x27;constant&#x27;, VarianceThreshold(threshold=0.02)),
                (&#x27;duplicated&#x27;, DropDuplicateFeatures())])</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" ><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">VarianceThreshold</label><div class="sk-toggleable__content"><pre>VarianceThreshold(threshold=0.02)</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox" ><label for="sk-estimator-id-4" class="sk-toggleable__label sk-toggleable__label-arrow">DropDuplicateFeatures</label><div class="sk-toggleable__content"><pre>DropDuplicateFeatures()</pre></div></div></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># or pipeline</span>
<span class="kn">from</span> <span class="nn">feature_engine.selection</span> <span class="kn">import</span> <span class="n">DropDuplicateFeatures</span><span class="p">,</span> <span class="n">DropConstantFeatures</span>

<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">DropConstantFeatures</span><span class="p">(</span><span class="n">tol</span><span class="o">=</span><span class="mf">0.998</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;duplicated&#39;</span><span class="p">,</span> <span class="n">DropDuplicateFeatures</span><span class="p">()),</span>
<span class="p">])</span>

<span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[(&#x27;constant&#x27;, DropConstantFeatures(tol=0.998)),
                (&#x27;duplicated&#x27;, DropDuplicateFeatures())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox" ><label for="sk-estimator-id-5" class="sk-toggleable__label sk-toggleable__label-arrow">Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[(&#x27;constant&#x27;, DropConstantFeatures(tol=0.998)),
                (&#x27;duplicated&#x27;, DropDuplicateFeatures())])</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox" ><label for="sk-estimator-id-6" class="sk-toggleable__label sk-toggleable__label-arrow">DropConstantFeatures</label><div class="sk-toggleable__content"><pre>DropConstantFeatures(tol=0.998)</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox" ><label for="sk-estimator-id-7" class="sk-toggleable__label sk-toggleable__label-arrow">DropDuplicateFeatures</label><div class="sk-toggleable__content"><pre>DropDuplicateFeatures()</pre></div></div></div></div></div></div></div></div></div>
</div>
</section>
<section id="correlation-features">
<h2><span class="section-number">4.1.4. </span>Correlation features<a class="headerlink" href="#correlation-features" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Select subset contain features highly <code class="docutils literal notranslate"><span class="pre">correlated</span></code> with <code class="docutils literal notranslate"><span class="pre">target</span></code>, but yet <code class="docutils literal notranslate"><span class="pre">uncorrelated</span></code> to each other.</p></li>
<li><p>Why need to handle correlated features in ML model ?</p>
<ul>
<li><p>Adding more correlated feature will add little information</p></li>
<li><p>High dimensionality</p></li>
<li><p>Affect to model interpretability</p></li>
<li><p>With different classifiers show the different sesitivity to correlation with target of each feature</p></li>
</ul>
</li>
<li><p>Type of correlation:</p>
<ul>
<li><p>Linear: pearson</p></li>
<li><p>Non-linear: kendall, spearman rank, mutual-information</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># load dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;Datasets/dataset_2.csv&#39;</span><span class="p">)</span>

<span class="c1"># separate dataset into train and test</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>  <span class="c1"># drop the target</span>
    <span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">],</span>  <span class="c1"># just the target</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((35000, 108), (15000, 108))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="k">def</span> <span class="nf">corr_heatmap</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;pearson&#39;</span><span class="p">):</span>
    <span class="n">corrmat</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">)</span>
    <span class="n">cmap</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">diverging_palette</span><span class="p">(</span><span class="mi">220</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">as_cmap</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span><span class="mi">11</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">corrmat</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">corr_scat</span><span class="p">(</span> <span class="n">var1</span><span class="p">,</span> <span class="n">var2</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">var1</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="n">var2</span><span class="p">])</span>
    <span class="n">corr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">var1</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[</span><span class="n">var2</span><span class="p">])[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">var2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">var1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;corr(</span><span class="si">{</span><span class="n">var1</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">var2</span><span class="si">}</span><span class="s1">) = </span><span class="si">{</span><span class="n">corr</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corr_scat</span><span class="p">(</span><span class="s1">&#39;var_1&#39;</span><span class="p">,</span> <span class="s1">&#39;var_28&#39;</span> <span class="p">,</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/0509347edb9e6fa9643533e19b086db034976af3286677c498c51c684196c891.png" src="../../_images/0509347edb9e6fa9643533e19b086db034976af3286677c498c51c684196c891.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corr_heatmap</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot: &gt;
</pre></div>
</div>
<img alt="../../_images/3a3afb7e0d26a08633e30e2172d7db185652236003c7217b8d6de750e82b2208.png" src="../../_images/3a3afb7e0d26a08633e30e2172d7db185652236003c7217b8d6de750e82b2208.png" />
</div>
</div>
<section id="brute-force-approach">
<h3><span class="section-number">4.1.4.1. </span>brute force approach<a class="headerlink" href="#brute-force-approach" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>it will remove the first feature that is correlated with anything else without any further insight.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">correlation</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">threshold</span><span class="p">):</span>
    
    <span class="c1"># create a set where I will store the names of correlated columns</span>
    <span class="n">col_corr</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    
    <span class="c1"># create the correlation matrix</span>
    <span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
    
    <span class="c1"># for each feature in the dataset (columns of the correlation matrix)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">)):</span>
        
        <span class="c1"># check with other features</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
            
            <span class="c1"># if the correlation is higher than a certain threshold</span>
            <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">corr_matrix</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">:</span> <span class="c1"># we are interested in absolute coeff value</span>
                
                <span class="c1"># print correlation, and variables examined</span>
                <span class="c1"># keep in mind that the columns and rows of the dataframe are identical</span>
                <span class="c1"># so we can identify the features being examned by looking for i,j</span>
                <span class="c1"># in the column names</span>
                <span class="nb">print</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">corr_matrix</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]),</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
                
                <span class="c1"># get the name of the correlated feature</span>
                <span class="n">colname</span> <span class="o">=</span> <span class="n">corr_matrix</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                
                <span class="c1"># and add it to our correlated set</span>
                <span class="n">col_corr</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">colname</span><span class="p">)</span>
                
    <span class="k">return</span> <span class="n">col_corr</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="highly-corr-group-approach">
<h3><span class="section-number">4.1.4.2. </span>highly corr group approach<a class="headerlink" href="#highly-corr-group-approach" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>The second approach looks to identify groups of highly correlated features. And then, we can make further investigation within these groups to decide which feature we keep and which one we remove.</p></li>
</ul>
<p><strong>In this group, several features are highly correlated. Which one should we keep and which ones should we remove?</strong></p>
<ul class="simple">
<li><p>One criteria to select which features to use from this group, would be to use those with <strong>less missing data</strong>.</p></li>
<li><p>Our dataset contains no missing values, so this is not an option. But keep this in mind when you work with your own datasets.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># build a dataframe with the correlation between features</span>
<span class="c1"># remember that the absolute value of the correlation</span>
<span class="c1"># coefficient is important and not the sign</span>

<span class="n">corrmat</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">corrmat</span> <span class="o">=</span> <span class="n">corrmat</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">unstack</span><span class="p">()</span> <span class="c1"># absolute value of corr coef</span>
<span class="n">corrmat</span> <span class="o">=</span> <span class="n">corrmat</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">corrmat</span> <span class="o">=</span> <span class="n">corrmat</span><span class="p">[</span><span class="n">corrmat</span> <span class="o">&gt;=</span> <span class="mf">0.8</span><span class="p">]</span>
<span class="n">corrmat</span> <span class="o">=</span> <span class="n">corrmat</span><span class="p">[</span><span class="n">corrmat</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">corrmat</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">corrmat</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">corrmat</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;feature1&#39;</span><span class="p">,</span> <span class="s1">&#39;feature2&#39;</span><span class="p">,</span> <span class="s1">&#39;corr&#39;</span><span class="p">]</span>
<span class="n">corrmat</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># find groups of correlated features</span>

<span class="n">grouped_feature_ls</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">correlated_groups</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">corrmat</span><span class="o">.</span><span class="n">feature1</span><span class="o">.</span><span class="n">unique</span><span class="p">():</span>
    
    <span class="k">if</span> <span class="n">feature</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">grouped_feature_ls</span><span class="p">:</span>

        <span class="c1"># find all features correlated to a single feature</span>
        <span class="n">correlated_block</span> <span class="o">=</span> <span class="n">corrmat</span><span class="p">[</span><span class="n">corrmat</span><span class="o">.</span><span class="n">feature1</span> <span class="o">==</span> <span class="n">feature</span><span class="p">]</span>
        <span class="n">grouped_feature_ls</span> <span class="o">=</span> <span class="n">grouped_feature_ls</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span>
            <span class="n">correlated_block</span><span class="o">.</span><span class="n">feature2</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span> <span class="o">+</span> <span class="p">[</span><span class="n">feature</span><span class="p">]</span>

        <span class="c1"># append the block of features to the list</span>
        <span class="n">correlated_groups</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">correlated_block</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;found </span><span class="si">{}</span><span class="s1"> correlated groups&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">correlated_groups</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;out of </span><span class="si">{}</span><span class="s1"> total features&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="correlation-with-feature-engine">
<h3><span class="section-number">4.1.4.3. </span>Correlation with Feature-engine<a class="headerlink" href="#correlation-with-feature-engine" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">DropCorrelatedFeatures</span></code> class from Feature-engine does a similar job to the <code class="docutils literal notranslate"><span class="pre">brute</span> <span class="pre">force</span> <span class="pre">approach</span></code> that we described earlier.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">SmartCorrelationSelection</span></code> allows us to select a feature from each correlated group based on model performance, number of missing values, cardinality or variance.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">feature_engine.selection</span> <span class="kn">import</span> <span class="n">DropCorrelatedFeatures</span><span class="p">,</span> <span class="n">SmartCorrelatedSelection</span>
</pre></div>
</div>
</div>
</div>
<section id="dropcorrelatedfeatures">
<h4><span class="section-number">4.1.4.3.1. </span>DropCorrelatedFeatures<a class="headerlink" href="#dropcorrelatedfeatures" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>drop features by threshold of correlation</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">feature_engine.selection</span> <span class="kn">import</span> <span class="n">DropCorrelatedFeatures</span>

<span class="c1"># set up the selector</span>
<span class="n">sel</span> <span class="o">=</span> <span class="n">DropCorrelatedFeatures</span><span class="p">(</span>
    <span class="n">threshold</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">method</span><span class="o">=</span><span class="s1">&#39;pearson&#39;</span><span class="p">,</span>
    <span class="n">missing_values</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span>
<span class="p">)</span>

<span class="c1"># find correlated features</span>
<span class="n">sel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># each set contains a group of correlated features</span>
<span class="n">sel</span><span class="o">.</span><span class="n">correlated_feature_sets_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[{&#39;var_3&#39;, &#39;var_80&#39;},
 {&#39;var_28&#39;, &#39;var_5&#39;, &#39;var_75&#39;},
 {&#39;var_11&#39;, &#39;var_33&#39;},
 {&#39;var_13&#39;, &#39;var_17&#39;},
 {&#39;var_15&#39;, &#39;var_57&#39;},
 {&#39;var_18&#39;, &#39;var_43&#39;},
 {&#39;var_19&#39;, &#39;var_29&#39;},
 {&#39;var_21&#39;, &#39;var_70&#39;, &#39;var_88&#39;},
 {&#39;var_22&#39;, &#39;var_24&#39;, &#39;var_32&#39;, &#39;var_39&#39;, &#39;var_42&#39;, &#39;var_76&#39;},
 {&#39;var_102&#39;, &#39;var_23&#39;},
 {&#39;var_26&#39;, &#39;var_59&#39;},
 {&#39;var_108&#39;, &#39;var_30&#39;},
 {&#39;var_35&#39;, &#39;var_87&#39;},
 {&#39;var_101&#39;, &#39;var_105&#39;, &#39;var_40&#39;, &#39;var_74&#39;, &#39;var_85&#39;},
 {&#39;var_46&#39;, &#39;var_94&#39;},
 {&#39;var_50&#39;, &#39;var_72&#39;},
 {&#39;var_52&#39;, &#39;var_66&#39;},
 {&#39;var_109&#39;, &#39;var_56&#39;},
 {&#39;var_104&#39;, &#39;var_60&#39;},
 {&#39;var_63&#39;, &#39;var_64&#39;, &#39;var_84&#39;, &#39;var_97&#39;},
 {&#39;var_106&#39;, &#39;var_77&#39;},
 {&#39;var_90&#39;, &#39;var_95&#39;},
 {&#39;var_100&#39;, &#39;var_98&#39;}]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># the transformer selects 1 feature from each group.</span>
<span class="c1"># the rest will be removed and can be found in this attribute</span>
<span class="n">sel</span><span class="o">.</span><span class="n">features_to_drop_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;var_100&#39;,
 &#39;var_101&#39;,
 &#39;var_102&#39;,
 &#39;var_104&#39;,
 &#39;var_105&#39;,
 &#39;var_106&#39;,
 &#39;var_108&#39;,
 &#39;var_109&#39;,
 &#39;var_17&#39;,
 &#39;var_24&#39;,
 &#39;var_28&#39;,
 &#39;var_29&#39;,
 &#39;var_32&#39;,
 &#39;var_33&#39;,
 &#39;var_39&#39;,
 &#39;var_42&#39;,
 &#39;var_43&#39;,
 &#39;var_57&#39;,
 &#39;var_59&#39;,
 &#39;var_64&#39;,
 &#39;var_66&#39;,
 &#39;var_70&#39;,
 &#39;var_72&#39;,
 &#39;var_74&#39;,
 &#39;var_75&#39;,
 &#39;var_76&#39;,
 &#39;var_80&#39;,
 &#39;var_84&#39;,
 &#39;var_85&#39;,
 &#39;var_87&#39;,
 &#39;var_88&#39;,
 &#39;var_94&#39;,
 &#39;var_95&#39;,
 &#39;var_97&#39;}
</pre></div>
</div>
</div>
</div>
</section>
<section id="smartcorrelationselection-by-performance">
<h4><span class="section-number">4.1.4.3.2. </span>SmartCorrelationSelection by Performance<a class="headerlink" href="#smartcorrelationselection-by-performance" title="Permalink to this heading">#</a></h4>
<p>We will keep a feature from each correlation group based on the performance of a random forest:</p>
<ul class="simple">
<li><p>For each feature from each correlation group, use <code class="docutils literal notranslate"><span class="pre">random</span> <span class="pre">forest</span></code> to get performance of model base on <code class="docutils literal notranslate"><span class="pre">scoring</span></code> metric</p></li>
<li><p>Select the feature of each group with highest performance</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">feature_engine.selection</span> <span class="kn">import</span> <span class="n">SmartCorrelatedSelection</span>

<span class="c1"># random forest</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,)</span>

<span class="c1"># correlation selector</span>
<span class="c1"># this may take a while, because we are training a random forest per correlation group</span>
<span class="n">sel</span> <span class="o">=</span> <span class="n">SmartCorrelatedSelection</span><span class="p">(</span>
    <span class="n">variables</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;pearson&quot;</span><span class="p">,</span>
    <span class="n">threshold</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">missing_values</span><span class="o">=</span><span class="s2">&quot;raise&quot;</span><span class="p">,</span>
    <span class="n">selection_method</span><span class="o">=</span><span class="s2">&quot;model_performance&quot;</span><span class="p">,</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">rf</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">sel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="smartcorrelationselection-by-variance">
<h4><span class="section-number">4.1.4.3.3. </span>SmartCorrelationSelection by Variance<a class="headerlink" href="#smartcorrelationselection-by-variance" title="Permalink to this heading">#</a></h4>
<p>Alternatively, we can select the feature with the highest variance from each group.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">feature_engine.selection</span> <span class="kn">import</span> <span class="n">SmartCorrelatedSelection</span>

<span class="c1"># correlation selector</span>
<span class="n">sel</span> <span class="o">=</span> <span class="n">SmartCorrelatedSelection</span><span class="p">(</span>
    <span class="n">variables</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;pearson&quot;</span><span class="p">,</span>
    <span class="n">threshold</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">missing_values</span><span class="o">=</span><span class="s2">&quot;raise&quot;</span><span class="p">,</span>
    <span class="n">selection_method</span><span class="o">=</span><span class="s2">&quot;variance&quot;</span><span class="p">,</span> <span class="c1"># &#39;cardinality&#39; if select feature with highest number of unique values</span>
    <span class="n">estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">sel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="pipeline">
<h4><span class="section-number">4.1.4.3.4. </span>pipeline<a class="headerlink" href="#pipeline" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># we stack all the selection methods inside a pipeline</span>

<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">DropConstantFeatures</span><span class="p">(</span><span class="n">tol</span><span class="o">=</span><span class="mf">0.998</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;duplicated&#39;</span><span class="p">,</span> <span class="n">DropDuplicateFeatures</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;correlation&#39;</span><span class="p">,</span> <span class="n">SmartCorrelatedSelection</span><span class="p">(</span><span class="n">selection_method</span><span class="o">=</span><span class="s1">&#39;variance&#39;</span><span class="p">)),</span>
<span class="p">])</span>

<span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="statistic-test">
<h2><span class="section-number">4.1.5. </span>Statistic test<a class="headerlink" href="#statistic-test" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Produce:</p>
<ul>
<li><p>S1: Rank features based on certain criteria / metrics</p></li>
<li><p>S2: Select features with highest rankings</p></li>
</ul>
</li>
<li><p>Advantages:</p>
<ul>
<li><p>Fast</p></li>
</ul>
</li>
<li><p>Disadvantages:</p>
<ul>
<li><p>Do not tracking the feature redundancy</p></li>
</ul>
</li>
</ul>
<p><strong>sklearn type of selection</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">SelectKBest</span></code>: select top k highest rank of pool</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SelectPercentile</span></code>: select top p% highest rank of pool</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SelectFdr</span></code>: (false discovery rate <code class="docutils literal notranslate"><span class="pre">FDR</span></code> = <code class="docutils literal notranslate"><span class="pre">FP</span></code> / (<code class="docutils literal notranslate"><span class="pre">FP</span></code> + <code class="docutils literal notranslate"><span class="pre">TP</span></code>) ) giới hạn xác suất bắt sai positive khi dự đoán <code class="docutils literal notranslate"><span class="pre">positive</span></code>: <code class="docutils literal notranslate"><span class="pre">FDR</span></code> &lt; <code class="docutils literal notranslate"><span class="pre">alpha</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SelectFpr</span></code>: (false positive rate <code class="docutils literal notranslate"><span class="pre">FPR</span></code> = <code class="docutils literal notranslate"><span class="pre">FP</span></code> / (<code class="docutils literal notranslate"><span class="pre">FP</span></code> + <code class="docutils literal notranslate"><span class="pre">TN</span></code>) ) giới hạn xác suất bắt sai <code class="docutils literal notranslate"><span class="pre">positive</span> <span class="pre">ngoài</span> <span class="pre">thực</span> <span class="pre">tế</span></code>: <code class="docutils literal notranslate"><span class="pre">FPR</span></code> &lt; <code class="docutils literal notranslate"><span class="pre">alpha</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SelectFwe</span></code>: (family wise error is the probability of incurring at least one false positive among all discoveries) Select the <code class="docutils literal notranslate"><span class="pre">pvalues</span></code> &lt; (<code class="docutils literal notranslate"><span class="pre">alpha</span></code>/<code class="docutils literal notranslate"><span class="pre">n_features</span></code>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">GenericUnivariateSelect</span></code>: add <code class="docutils literal notranslate"><span class="pre">mode</span></code> to select {<code class="docutils literal notranslate"><span class="pre">percentile</span></code>, <code class="docutils literal notranslate"><span class="pre">k_best</span></code>, <code class="docutils literal notranslate"><span class="pre">fpr</span></code>, <code class="docutils literal notranslate"><span class="pre">fdr</span></code>, <code class="docutils literal notranslate"><span class="pre">fwe</span></code>}, default=<code class="docutils literal notranslate"><span class="pre">percentile</span></code></p></li>
</ul>
<section id="mutual-information">
<h3><span class="section-number">4.1.5.1. </span>Mutual information<a class="headerlink" href="#mutual-information" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Mutual</span> <span class="pre">information</span></code> is a measure of the mutual dependence of 2 variables, in others words, quanlifies the amount of information gained about 1 random variables through observing the other. The mutual information measures the reduction in uncertainty in variable A when variable B is known.</p></li>
<li><p>To select variables, we are interested in the <code class="docutils literal notranslate"><span class="pre">mutual</span> <span class="pre">information</span></code> between the <code class="docutils literal notranslate"><span class="pre">predictor</span> <span class="pre">variables</span></code> and the <code class="docutils literal notranslate"><span class="pre">target</span></code>. Higher mutual information values, indicate little uncertainty about the target <code class="docutils literal notranslate"><span class="pre">Y</span></code> given the predictor <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p></li>
</ul>
<p><strong>Produce</strong></p>
<ul class="simple">
<li><p>Step 1: Calculate the MI by <code class="docutils literal notranslate"><span class="pre">Mutual_info_classif</span></code> (target binary Y), <code class="docutils literal notranslate"><span class="pre">Mutual_info_regression</span></code> (target continuous Y), and Rank the features</p></li>
<li><p>Step 2: Select features by <code class="docutils literal notranslate"><span class="pre">SelectKBest</span></code> (top k highest ranking), or <code class="docutils literal notranslate"><span class="pre">SelectPercentile</span></code> (top percentile of highest rank)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to obtain the mutual information values</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">mutual_info_classif</span><span class="p">,</span> <span class="n">mutual_info_regression</span>

<span class="c1"># to select the features</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">SelectPercentile</span>

<span class="c1"># calculate the mutual information between the variables and the target</span>
<span class="c1"># the smaller the value of the mi, the less information we can infer from the feature about the target</span>
<span class="n">mi</span> <span class="o">=</span> <span class="n">mutual_info_classif</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># 1) let&#39;s capture the above array in a pandas series</span>
<span class="c1"># 2)add the variable names in the index</span>
<span class="c1"># 3) sort the features based on their mutual information value</span>
<span class="c1"># 4) and make a var plot</span>

<span class="n">mi</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">mi</span><span class="p">)</span>
<span class="n">mi</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span>
<span class="n">mi</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Mutual Information&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Mutual Information&#39;)
</pre></div>
</div>
<img alt="../../_images/3cd5a9f8a89a6a708bc74ee1104c379524f766705d441b859af7a0304e2b2e5e.png" src="../../_images/3cd5a9f8a89a6a708bc74ee1104c379524f766705d441b859af7a0304e2b2e5e.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Select top k features based on MI</span>
<span class="c1"># here we will select the top 10 features based on their mutual information value</span>

<span class="c1"># select features</span>
<span class="n">sel_</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">mutual_info_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># display features</span>
<span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">sel_</span><span class="o">.</span><span class="n">get_support</span><span class="p">()]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;var_6&#39;, &#39;var_7&#39;, &#39;var_16&#39;, &#39;var_33&#39;, &#39;var_34&#39;, &#39;var_48&#39;, &#39;var_55&#39;,
       &#39;var_69&#39;, &#39;var_96&#39;, &#39;var_108&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Select the features in the top percentile</span>
<span class="n">sel_</span> <span class="o">=</span> <span class="n">SelectPercentile</span><span class="p">(</span><span class="n">mutual_info_classif</span><span class="p">,</span> <span class="n">percentile</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># display the features</span>
<span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">sel_</span><span class="o">.</span><span class="n">get_support</span><span class="p">()]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;var_6&#39;, &#39;var_7&#39;, &#39;var_14&#39;, &#39;var_16&#39;, &#39;var_33&#39;, &#39;var_34&#39;, &#39;var_55&#39;,
       &#39;var_69&#39;, &#39;var_91&#39;, &#39;var_96&#39;, &#39;var_108&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="chi-square-test">
<h3><span class="section-number">4.1.5.2. </span>Chi-square test<a class="headerlink" href="#chi-square-test" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Working with non-negative categorical features and categorical target (binary or multiclass).</p></li>
<li><p>Chi-square used to determine if 2 samples of categorical features were extracted from the same population</p>
<ul>
<li><p>Samples is splited by each class of target in categorical variable.</p></li>
<li><p>If samples are in the sample population, meaning there are no different from samples of categorical variables that are seperated by each target class. Thus, the categorical variable is not predictive in target.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">chi2</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_wine</span>

<span class="c1"># Loading wine data</span>
<span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="n">load_wine</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">as_frame</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="n">test</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">score_func</span><span class="o">=</span><span class="n">chi2</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">fit</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">X_new</span><span class="o">=</span><span class="n">test</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f_score</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">chi2</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">chi2test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">p_value</span><span class="p">)</span>
<span class="n">chi2test</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span>
<span class="n">chi2test</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot: &gt;
</pre></div>
</div>
<img alt="../../_images/bb0e09e07a0c27f55ea33e690c3e6bfb9b310b980cea8c58535d99252fb3894e.png" src="../../_images/bb0e09e07a0c27f55ea33e690c3e6bfb9b310b980cea8c58535d99252fb3894e.png" />
</div>
</div>
</section>
<section id="univariate-selection-anova">
<h3><span class="section-number">4.1.5.3. </span>Univariate selection (anova)<a class="headerlink" href="#univariate-selection-anova" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Univariate feature selection works by selecting the best features based on univariate statistical tests (ANOVA). The methods estimate the degree of linear dependency between two random variables. In this case, any of the predictor variables and the target.</p></li>
<li><p><strong>Assumption</strong>: ANOVA assumes a linear relationship between the feature and the target and that the variables follow a Gaussian distribution. If this is not true, the result of this test may not be useful. These may not always be the case for the variables in your dataset, so if looking to implement these procedure, you will need to corroborate these assumptions.</p></li>
<li><p>Need to transform features to normal shape and linear relationship before use selection process</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># With assume that the variables show a linear relationship with the target and that they are normally distributed.</span>

<span class="c1"># to determine the p-values with anova</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">f_classif</span><span class="p">,</span> <span class="n">f_regression</span>

<span class="c1"># to select features</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">SelectPercentile</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># calculate the univariate statistical measure between each of the variables and the target</span>
<span class="c1"># similarly to chi2, the output is one array with f-scores and one array with the pvalues</span>

<span class="n">f_score</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">f_classif</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>


<span class="c1"># 1) let&#39;s capture the pvalues in a pandas series</span>
<span class="c1"># 2) add the variable names in the index</span>
<span class="c1"># 3) sort the features based on their anova pvalues</span>
<span class="c1"># 4) and make a var plot</span>

<span class="n">univariate</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">p_value</span><span class="p">)</span>
<span class="n">univariate</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span>
<span class="n">univariate</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot: &gt;
</pre></div>
</div>
<img alt="../../_images/dda20f3feadb7ca31b5a5acd44a5db3325ec000351f70f04e562c09c2876d73e.png" src="../../_images/dda20f3feadb7ca31b5a5acd44a5db3325ec000351f70f04e562c09c2876d73e.png" />
</div>
</div>
<p>The smaller the p_value the more predictive the feature is.</p>
<p>Features on the left of the plot are very bad at predicting the target. The most predictive features are on the right of the plot.</p>
<p><strong>How can we select features based on the anova p-values?</strong></p>
<p>There are a few ways in which this can be done:</p>
<ul class="simple">
<li><p>Select top k features, where k is an arbitrary number of features</p></li>
<li><p>Select features in the top n percentile, where n is again an arbitrary number</p></li>
<li><p>Select all features below a certain threshold, arbitrarily decided.</p></li>
</ul>
<p>Scikit-learn transformer <strong>SelectKBest</strong>, allows us to automatically select the top k features, based of any statistical value, including Anova. It will select those with the lowest pvalues.</p>
<p>Sklearn’s <strong>SelectPercentile</strong> allows us to select the features in the top percentile of any statistical value, including the anova.</p>
<p>Alternatively, if we want to select features based on a pvalue threshold, we can do it manually.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># select the top 10 features</span>
<span class="n">sel_</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># display selected feature names</span>
<span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">sel_</span><span class="o">.</span><span class="n">get_support</span><span class="p">()]</span>

<span class="c1"># remove unwanted features from the dataset</span>
<span class="n">X_train_sl</span> <span class="o">=</span> <span class="n">sel_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="univariate-with-model-performance">
<h2><span class="section-number">4.1.6. </span>Univariate with model performance<a class="headerlink" href="#univariate-with-model-performance" title="Permalink to this heading">#</a></h2>
<p>This procedure works as follows:</p>
<ul class="simple">
<li><p>Train a ML model per every single feature</p></li>
<li><p>Determine the performance of the models</p></li>
<li><p>Select features if model performance is above a certain threshold</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">mean_squared_error</span>

<span class="kn">from</span> <span class="nn">feature_engine.selection</span> <span class="kn">import</span> <span class="n">SelectBySingleFeaturePerformance</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># set up a machine learning model</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># set up the selector</span>
<span class="n">sel</span> <span class="o">=</span> <span class="n">SelectBySingleFeaturePerformance</span><span class="p">(</span>
    <span class="n">variables</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">rf</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># find predictive features</span>
<span class="n">sel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1">#  the transformer stores a dictionary of feature:metric pairs</span>
<span class="c1"># in this case is the roc_auc of each individual model</span>
<span class="c1"># we can plot feature importance sorted by importance</span>

<span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">sel</span><span class="o">.</span><span class="n">feature_performance_</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Performance of ML models trained with individual features&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;roc-auc&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;roc-auc&#39;)
</pre></div>
</div>
<img alt="../../_images/b71bffe7dfca74be48c08dde1cbba6a53bfad7acf0aa141a2da4afb796842938.png" src="../../_images/b71bffe7dfca74be48c08dde1cbba6a53bfad7acf0aa141a2da4afb796842938.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># remove non-prective features</span>

<span class="n">X_train_sl</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_sl</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">X_train_sl</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test_sl</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="target-mean-encoding-selection">
<h2><span class="section-number">4.1.7. </span>Target mean encoding selection<a class="headerlink" href="#target-mean-encoding-selection" title="Permalink to this heading">#</a></h2>
<p><strong>The procedure consists in the following steps</strong>:</p>
<ol class="arabic simple">
<li><p>For each categorical variable:</p></li>
</ol>
<ul class="simple">
<li><p>1.1. Separate into train and test</p></li>
<li><p>1.2. Determine the mean value of the target within each label of the categorical variable using the train set</p></li>
<li><p>1.3. Use that mean target value per label as the prediction (using the test set) and calculate the roc-auc.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>For each numerical variable:</p></li>
</ol>
<ul class="simple">
<li><p>2.1. Separate into train and test</p></li>
<li><p>2.2. Divide the variable into 100 quantiles</p></li>
<li><p>2.3. Calculate the mean target within each quantile using the training set</p></li>
<li><p>2.4. Use that mean target value / bin as the prediction (using the test set) and calculate the roc-auc</p></li>
</ul>
<p><strong>Advantages</strong>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Speed</span></code>: computing mean and quantiles is direct and efficient</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Stability</span> <span class="pre">respect</span> <span class="pre">to</span> <span class="pre">scale</span></code>: extreme values for continuous variables do not skew the predictions</p></li>
<li><p>Comparable between categorical and numerical variables</p></li>
<li><p>Accommodation of non-linearities</p></li>
</ul>
<p><strong>Challenge</strong>:</p>
<ul class="simple">
<li><p>We can use any performance metric, and difference metrics may lead to difference selected features:</p>
<ul>
<li><p>Classification: ROC_AUC, accuracy, precision, recall,…</p></li>
<li><p>Regression: MSE, RMSE, R2,…</p></li>
</ul>
</li>
</ul>
<p><strong>Reference</strong>:
<a class="reference external" href="http://www.mtome.com/Publications/CiML/CiML-v3-book.pdf">Predicting customer behaviour: The University of Melbourne’s KDD Cup Report. Miller et al. JMLR Workshop and Conference Proceedings 7:45-55</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Feature-engine automatically detects categorical and numerical variables.</span>
<span class="kn">from</span> <span class="nn">feature_engine.selection</span> <span class="kn">import</span> <span class="n">SelectByTargetMeanPerformance</span>

<span class="c1"># feautre engine automates the selection for both</span>
<span class="c1"># categorical and numerical variables</span>

<span class="n">sel</span> <span class="o">=</span> <span class="n">SelectByTargetMeanPerformance</span><span class="p">(</span>
    <span class="n">variables</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># automatically finds categorical and numerical variables</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span> <span class="c1"># the metric to evaluate performance</span>
    <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="c1"># the threshold for feature selection, </span>
    <span class="n">bins</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="c1"># the number of intervals to discretise the numerical variables</span>
    <span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;equal_frequency&quot;</span><span class="p">,</span> <span class="c1"># whether the intervals should be of equal size or equal number of observations</span>
    <span class="n">cv</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="c1"># cross validation</span>
    <span class="n">regression</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="c1"># whether this is regression or classification</span>
<span class="p">)</span>

<span class="n">sel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-6" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>SelectByTargetMeanPerformance(bins=3, cv=2, strategy=&#x27;equal_frequency&#x27;,
                              threshold=0.5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-10" type="checkbox" checked><label for="sk-estimator-id-10" class="sk-toggleable__label sk-toggleable__label-arrow">SelectByTargetMeanPerformance</label><div class="sk-toggleable__content"><pre>SelectByTargetMeanPerformance(bins=3, cv=2, strategy=&#x27;equal_frequency&#x27;,
                              threshold=0.5)</pre></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_sl</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_sl</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">X_train_sl</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test_sl</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((35000, 95), (15000, 95))
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./1_Process_Modelling/Split_notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="0_toc_fs.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">4. </span>Overview of feature selection</p>
      </div>
    </a>
    <a class="right-next"
       href="3_Feature_selection_and_decomposition-2.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">4.2. </span>Wrapped methods</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#constant-features">4.1.1. Constant features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quasi-constant-features">4.1.2. Quasi-constant features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#duplicated-features">4.1.3. Duplicated features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-features">4.1.4. Correlation features</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#brute-force-approach">4.1.4.1. brute force approach</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#highly-corr-group-approach">4.1.4.2. highly corr group approach</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-with-feature-engine">4.1.4.3. Correlation with Feature-engine</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#dropcorrelatedfeatures">4.1.4.3.1. DropCorrelatedFeatures</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#smartcorrelationselection-by-performance">4.1.4.3.2. SmartCorrelationSelection by Performance</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#smartcorrelationselection-by-variance">4.1.4.3.3. SmartCorrelationSelection by Variance</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pipeline">4.1.4.3.4. pipeline</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistic-test">4.1.5. Statistic test</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mutual-information">4.1.5.1. Mutual information</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#chi-square-test">4.1.5.2. Chi-square test</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#univariate-selection-anova">4.1.5.3. Univariate selection (anova)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#univariate-with-model-performance">4.1.6. Univariate with model performance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#target-mean-encoding-selection">4.1.7. Target mean encoding selection</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Khổng Tiến Đạt
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>